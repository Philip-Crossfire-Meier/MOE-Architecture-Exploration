{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354b2fcd",
   "metadata": {},
   "source": [
    "\n",
    "# MoE Metrics Data Analysis Notebook\n",
    "\n",
    "How to run this notebook:\n",
    "- Select the dataset used in the experiments you want to analyze in cell 0 (the cell after this markdown cell).\n",
    "- Optionally add tags for inclusion or exclusion\n",
    "- Run all or individual cells.\n",
    "- If you already created a csv export you can skip the first cell in section 'Expert Activation Heatmaps' (takes a long time to execute)\n",
    "\n",
    "Dependencies:\n",
    "- aimStack\n",
    "- SNS (Seaborn)\n",
    "- Matplotlib\n",
    "- PyPlot\n",
    "- Numpy\n",
    "- Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76411f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Select the dataset for which to run analysis\n",
    "\"\"\"\n",
    "from typing import Literal\n",
    "\n",
    "dataset: Literal['mnist', 'cifar10', 'cinic10'] = 'cifar10' # mnist or cifar10 or cinic10\n",
    "include_tags = [] # Tags of experiments to include, empty list means include all\n",
    "exclude_tags = [] # Tags of experiments to exclude, empty list means exclude none\n",
    "\n",
    "bootstrap_reps = 1000 # Number of bootstrap repetitions for confidence intervals\n",
    "last_runs_to_consider = 10 # Some calculations that compare different architectures need an equal amount of runs for each architecture.\n",
    "\n",
    "repo_path = '../..' # The (relative) path to the aim repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e543e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Common imports and definitions\n",
    "This cell contains common imports, definitions and functions for subsequent cells\n",
    "\"\"\"\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from aim import Repo\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "warnings.filterwarnings('default')\n",
    "\n",
    "RAND_STATE = np.random.RandomState(42)\n",
    "\n",
    "def common():\n",
    "    from aim import Repo\n",
    "    repo = Repo(repo_path)\n",
    "\n",
    "    # Friendly model names for table display only\n",
    "    models_friendly_names = {\n",
    "        'softmoe': 'SoftMoE',\n",
    "        'noisytopk': 'Top-k',\n",
    "        'expert_choice': 'Expert Choice',\n",
    "        'ffn': 'FFN',\n",
    "        'roundrobin': 'Round Robin',\n",
    "        'expert_segmentation': 'Expert Segmentation',\n",
    "        'switch_transformer': 'Switch Transformer'\n",
    "    }\n",
    "\n",
    "    # ...likewise for columns\n",
    "    column_friendly_names = {\n",
    "        \"moe_type\": \"MoE Type\",\n",
    "        \"step\": \"Step\",\n",
    "        \"epoch\": \"Epoch\",\n",
    "        \"accuracy\": \"Accuracy\",\n",
    "        \"profiling_memory_usage\": \"Memory Usage\",\n",
    "        \"profiling_total_cpu_time\": \"Total CPU Time\",\n",
    "        \"loss\": \"Loss\",\n",
    "        \"macs\": \"MACs\",\n",
    "        \"expert_activations\": \"Expert Activations\"\n",
    "    }\n",
    "\n",
    "    return repo, models_friendly_names, column_friendly_names\n",
    "\n",
    "repo, models_friendly_names, column_friendly_names = common()\n",
    "\n",
    "# Set color palette and style\n",
    "COLORS = sns.color_palette('colorblind')\n",
    "COLORS_IDX = [0, 3, 4, 2, 1, 7, 8]\n",
    "MOE_ARCH_COLOR_DICT = dict(zip(models_friendly_names.keys(), [COLORS[idx] for idx in COLORS_IDX]))\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "COMMON_CELLS = True # This just tells subsequent cells that this particular cell has been executed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2625b762",
   "metadata": {},
   "source": [
    "The next cell queries the aim repo for metrics of interest, then builds two dataframes:\n",
    "- accuracy_df : used in subsequent analysis steps\n",
    "- accuracy_df_styled : based on accuracy_df and intended for direct export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43250f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mean, Max and Min metrics data query\n",
    "\"\"\"\n",
    "try:\n",
    "    if COMMON_CELLS:\n",
    "        pass\n",
    "except NameError:\n",
    "    from IPython.display import Javascript\n",
    "    Javascript(\"Jupyter.notebook.execute_cells([0,1])\") \n",
    "\n",
    "seq = repo.query_metrics(f\"metric.name in ['loss', 'accuracy', 'profiling_total_cpu_time', 'profiling_memory_usage'] \\\n",
    "                         and metric.context.subset == 'val' or ((metric.name == 'macs' or metric.name.startswith('expert_')) and metric.context.subset == 'train') \\\n",
    "                         \")\n",
    "\n",
    "all_rows = []\n",
    "df_activations = defaultdict(list)\n",
    "\n",
    "for metric in seq:\n",
    "    if dataset not in metric.run.props.tags or set(exclude_tags).intersection(set(metric.run.props.tags)):\n",
    "        continue\n",
    "    \n",
    "    # Find MoE type for this metric in run tags\n",
    "    model = \"\"\n",
    "    for model in models_friendly_names.keys():\n",
    "        if model in metric.run.props.tags:\n",
    "            model = model\n",
    "            break\n",
    "        \n",
    "    for x in metric.data:\n",
    "        step = x[0]\n",
    "        data = x[1]\n",
    "        epoch = data[1]\n",
    "        value = data[0]\n",
    "        \n",
    "        if metric.name.startswith('expert_'):\n",
    "            df_activations[metric.run.hash, step, epoch, model].append(value)\n",
    "           \n",
    "        else:\n",
    "            all_rows.append({\n",
    "                \"hash\": metric.run.hash,\n",
    "                \"moe_type\": model,\n",
    "                \"context\": \"val\",\n",
    "                \"step\": step,\n",
    "                \"epoch\": epoch,\n",
    "                \"metric_name\": metric.name,\n",
    "                \"value\": value\n",
    "            })\n",
    "\n",
    "\n",
    "for (hash, step, epoch, model), values in df_activations.items():\n",
    "    all_rows.append({\n",
    "        \"hash\": hash,\n",
    "        \"moe_type\": model,\n",
    "        \"context\": \"train\",\n",
    "        \"step\": step,\n",
    "        \"epoch\": epoch,\n",
    "        \"metric_name\": \"expert_activations\",\n",
    "        \"value\": values\n",
    "    })\n",
    "df = pd.DataFrame(all_rows)\n",
    "\n",
    "accuracy_df = df.pivot_table(\n",
    "    index=['hash', 'moe_type', 'context', 'step', 'epoch'],\n",
    "    columns='metric_name',\n",
    "    values='value',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "accuracy_df.columns.name = None\n",
    "\n",
    "print(f\"Shape: {accuracy_df.shape}\")\n",
    "print(f\"Columns: {list(accuracy_df.columns)}\")\n",
    "\n",
    "accuracy_df_styled = accuracy_df.style.format({\n",
    "    \"hash\": \"{:s}\",\n",
    "    \"moe_type\": lambda x: models_friendly_names.get(x, x),\n",
    "    \"context\": \"{:s}\",\n",
    "    \"step\": \"{:.0f}\",\n",
    "    \"epoch\": \"{:.0f}\",\n",
    "    \"accuracy\": \"{:.3f}\",\n",
    "    \"profiling_memory_usage\": \"{:.0f}\",\n",
    "    \"profiling_total_cpu_time\": \"{:.2f}\",\n",
    "    \"macs\": \"{:.0f}\",\n",
    "    \"expert_activations\": \"{:.0f}\"\n",
    "}).hide(axis=0).hide(subset=['hash', 'context'], axis=1).relabel_index([new for old,new in column_friendly_names.items()], axis=1)\n",
    "accuracy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18368f59",
   "metadata": {},
   "source": [
    "## Group metrics and calculate mean/min/max\n",
    "The next two cells group the metrics a) by MoE and epoch and b) only by MoE for exporting a summary table.\n",
    "### Group by MoE and Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af634982",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mean, Max and Min metrics table generation\n",
    "\"\"\"\n",
    "try:\n",
    "    if COMMON_CELLS:\n",
    "        pass\n",
    "except NameError:\n",
    "    from IPython.display import Javascript\n",
    "    Javascript(\"Jupyter.notebook.execute_cells([0,1])\") \n",
    "\n",
    "# We need dummy entries because styler.relabel doesn't properly handle levels in multi column indexes\n",
    "column_friendly_names_2 = {\n",
    "    \"moe_type\": \"MoE Type\",\n",
    "    \"epoch\": \"Epoch\",\n",
    "    \"accuracy\": \"Accuracy\",\n",
    "    \"profiling_memory_usage\": \"Memory Usage\",\n",
    "    \"profiling_total_cpu_time\": \"Total CPU Time\",\n",
    "    \"placeholder_1\": \"Memory Usage\",\n",
    "    \"placeholder_2\": \"placeholder\",\n",
    "    \"placeholder_3\": \"placeholder\",\n",
    "    \"placeholder_4\": \"Total CPU Time\",\n",
    "    \"placeholder_5\": \"placeholder\",\n",
    "    \"placeholder_6\": \"placeholder\",\n",
    "    \"macs\": \"MACs\",\n",
    "    \"loss\": \"Loss\",\n",
    "    \"placeholder_7\": \"placeholder\",\n",
    "    \"placeholder_8\": \"placeholder\",\n",
    "}\n",
    "\n",
    "accuracy_grouped = accuracy_df.groupby([\"moe_type\", \"epoch\"]).agg({\"accuracy\": [\"mean\", \"min\", \"max\"], \"profiling_memory_usage\": [\"mean\", \"min\", \"max\"], \"profiling_total_cpu_time\": [\"mean\", \"min\", \"max\"], \"macs\": [\"max\"], \"loss\": [\"mean\", \"min\", \"max\"]}).reset_index()\n",
    "accuracy_grouped\n",
    "formatter = {\n",
    "    (\"moe_type\", \"\"): lambda x: models_friendly_names.get(x, x),\n",
    "    (\"epoch\", \"\"): \"{:.0f}\",\n",
    "    (\"accuracy\", \"mean\"): \"{:.3f}\",\n",
    "    (\"accuracy\", \"min\"): \"{:.3f}\",\n",
    "    (\"accuracy\", \"max\"): \"{:.3f}\",\n",
    "    (\"profiling_memory_usage\", \"mean\"): \"{:.0f}\",\n",
    "    (\"profiling_memory_usage\", \"min\"): \"{:.0f}\",\n",
    "    (\"profiling_memory_usage\", \"max\"): \"{:.0f}\",\n",
    "    (\"profiling_total_cpu_time\", \"mean\"): \"{:.2f}\",\n",
    "    (\"profiling_total_cpu_time\", \"min\"): \"{:.2f}\",\n",
    "    (\"profiling_total_cpu_time\", \"max\"): \"{:.2f}\",\n",
    "    (\"macs\", \"\"): \"{:.0f}\",\n",
    "    (\"loss\", \"mean\"): \"{:.3f}\",\n",
    "    (\"loss\", \"min\"): \"{:.3f}\",\n",
    "    (\"loss\", \"max\"): \"{:.3f}\"\n",
    "}\n",
    "accuracy_grouped_styled = accuracy_grouped.style.format(formatter).hide(axis=0).relabel_index(labels=[new for old, new in column_friendly_names_2.items()], axis=1, level=0)\n",
    "print(accuracy_grouped_styled.to_latex(f\"../../report/appendices/model_accuracy_progression_table_{dataset}.tex\", environment=\"longtblr\"))\n",
    "accuracy_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864372fb",
   "metadata": {},
   "source": [
    "### Group by MoE only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceb50a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Group by MoE architecture\n",
    "\"\"\"\n",
    "try:\n",
    "    if COMMON_CELLS:\n",
    "        pass\n",
    "except NameError:\n",
    "    from IPython.display import Javascript\n",
    "    Javascript(\"Jupyter.notebook.execute_cells([0,1])\") \n",
    "    \n",
    "# Only group by moe type for the summary table\n",
    "column_friendly_names_3 = {key: value for key, value in column_friendly_names_2.items() if key != \"epoch\"}\n",
    "\n",
    "accuracy_grouped_2 = accuracy_df.groupby(\"moe_type\").agg({\"accuracy\": [\"mean\", \"min\", \"max\"], \"profiling_memory_usage\": [\"mean\", \"min\", \"max\"], \"profiling_total_cpu_time\": [\"mean\", \"min\", \"max\"], \"macs\": [\"max\"], \"loss\": [\"mean\", \"min\", \"max\"]}).reset_index()\n",
    "accuracy_grouped_2_styled = accuracy_grouped_2.style.format(formatter).hide(axis=0).relabel_index(labels=[new for old, new in column_friendly_names_3.items()], axis=1, level=0)\n",
    "accuracy_grouped_2_styled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884ab0c8",
   "metadata": {},
   "source": [
    "## Accuracy and Loss Charts\n",
    "\n",
    "This cell plots and saves accuracy and loss charts. For this, the min, max and mean (based on the exponential moving average) are picked/calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f951b57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Accuracy and Loss Charts\n",
    "References: \n",
    "- https://stackoverflow.com/questions/76317946/calculate-exponential-moving-average-using-pandas-dataframe\n",
    "- https://www.geeksforgeeks.org/pandas/how-to-calculate-moving-average-in-a-pandas-dataframe/\n",
    "\"\"\"\n",
    "try:\n",
    "    if COMMON_CELLS:\n",
    "        pass\n",
    "except NameError:\n",
    "    from IPython.display import Javascript\n",
    "    Javascript(\"Jupyter.notebook.execute_cells([0,1])\") \n",
    "\n",
    "def exponential_moving_average(data, alpha=0.3):\n",
    "    if len(data) == 0:\n",
    "        return data\n",
    "    cleaned = data.dropna()\n",
    "    if cleaned.iloc[0] is float('nan'):\n",
    "        smoothed = [0]\n",
    "    else:\n",
    "        smoothed = [cleaned.iloc[0]]\n",
    "    \n",
    "    for i in range(1, len(cleaned)):\n",
    "        smoothed.append(alpha * cleaned.iloc[i] + (1 - alpha) * smoothed[-1])\n",
    "    return pd.Series(smoothed, index=cleaned.index)\n",
    "\n",
    "models = [model for model in accuracy_grouped['moe_type'].unique() if model]\n",
    "for model in models:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    individual_runs = accuracy_df[accuracy_df['moe_type'] == model]\n",
    "    \n",
    "    for i, hash_val in enumerate(individual_runs['hash'].unique()):\n",
    "        run_data = individual_runs[individual_runs['hash'] == hash_val].sort_values('epoch')\n",
    "        \n",
    "        if len(run_data) > 0:\n",
    "            smoothed_accuracy = exponential_moving_average(run_data['accuracy'], alpha=0.3) \n",
    "            sns.lineplot(x=run_data['epoch'], y=smoothed_accuracy, color='lightgray', linewidth=2.0, ax=ax)\n",
    "           \n",
    "    \n",
    "    subset = accuracy_grouped[accuracy_grouped['moe_type'] == model].sort_values('epoch')\n",
    "    \n",
    "    if len(subset) > 0:\n",
    "        # Smooth aggregate data\n",
    "        smoothed_mean = exponential_moving_average(subset['accuracy']['mean'], alpha=0.3)\n",
    "        smoothed_min = exponential_moving_average(subset['accuracy']['min'], alpha=0.3)\n",
    "        smoothed_max = exponential_moving_average(subset['accuracy']['max'], alpha=0.3)\n",
    "        loss_mean = exponential_moving_average(subset['loss']['mean'], alpha=0.3)\n",
    "        \n",
    "        # Accuracy Mean line\n",
    "        sns.lineplot(x=subset['epoch'], y=smoothed_mean, label='Accuracy Mean', linewidth=3, ax=ax)\n",
    "\n",
    "        # Accuracy Min/max lines\n",
    "        sns.lineplot(x=subset['epoch'], y=smoothed_min, color='gray', linestyle='--', alpha=0.8, linewidth=2.0, label='Accuracy Min', ax=ax)\n",
    "        sns.lineplot(x=subset['epoch'], y=smoothed_max, color='gray', linestyle=':', alpha=0.8, linewidth=2.0, label='Accuracy Max', ax=ax)\n",
    "\n",
    "        # Loss Mean line\n",
    "        sns.lineplot(x=subset['epoch'], y=loss_mean, label='Loss Mean', linewidth=3, ax=ax)\n",
    "\n",
    "    friendly_name = models_friendly_names.get(model, model)\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('Accuracy', fontsize=12)\n",
    "    ax.set_ylim(0.0, 2.5)\n",
    "    \n",
    "    ax.legend(fontsize=12, loc='lower right', fancybox=True)\n",
    "    sns.despine(ax=ax)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    safe_filename = model.replace(' ', '_').lower()\n",
    "    plt.savefig(f'../../report/charts/accuracy_{safe_filename}_{dataset}.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3342bc07",
   "metadata": {},
   "source": [
    "## Hardware Usage Charts\n",
    "\n",
    "The next two cells plot and save the hardware usage charts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5e40dd",
   "metadata": {},
   "source": [
    "### Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a439f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot Memory Usage\n",
    "References:\n",
    "- https://seaborn.pydata.org/generated/seaborn.lineplot.html\n",
    "- https://seaborn.pydata.org/examples/timeseries_facets.html\n",
    "- https://stackoverflow.com/questions/62667158/how-do-i-increase-the-line-thickness-for-sns-lineplot\n",
    "\"\"\"\n",
    "try:\n",
    "    if COMMON_CELLS:\n",
    "        pass\n",
    "except NameError:\n",
    "    from IPython.display import Javascript\n",
    "    Javascript(\"Jupyter.notebook.execute_cells([0,1])\") \n",
    "\n",
    "memory_data = []\n",
    "for idx, model in enumerate(models):\n",
    "    individual_runs = accuracy_df[accuracy_df['moe_type'] == model]\n",
    "    for _, row in individual_runs.iterrows():\n",
    "        memory_data.append({\n",
    "            'epoch': row['epoch'],\n",
    "            'memory_usage': row['profiling_memory_usage'],\n",
    "            'moe_type': model,\n",
    "            'friendly_name': models_friendly_names.get(model, model),\n",
    "            'hash': row['hash']\n",
    "        })\n",
    "\n",
    "memory_df = pd.DataFrame(memory_data)\n",
    "\n",
    "# Calculate mean for each model/epoch combination\n",
    "mean_data = memory_df.groupby(['friendly_name', 'epoch'])['memory_usage'].mean().reset_index()\n",
    "mean_data['line_type'] = 'Mean'\n",
    "\n",
    "g = sns.FacetGrid(memory_df, col='friendly_name', col_wrap=3, height=4, aspect=1.2, sharey=False)\n",
    "\n",
    "# Plot individual runs\n",
    "g.map_dataframe(sns.lineplot, x='epoch', y='memory_usage', units='hash', estimator=None, alpha=0.6, linewidth=1.5, marker='o', markersize=3)\n",
    "\n",
    "# Overlay mean lines to make it stand out\n",
    "def add_mean_line(data, **kwargs):\n",
    "    color = MOE_ARCH_COLOR_DICT.get(data.moe_type.iloc[0], 'gray')\n",
    "    mean_by_epoch = data.groupby('epoch')['memory_usage'].mean()\n",
    "    sns.lineplot(mean_by_epoch, label='Mean', linewidth=3, color=color)\n",
    "\n",
    "g.map_dataframe(add_mean_line)\n",
    "  \n",
    "# Set individual run colors to gray\n",
    "for ax in g.axes.flatten():\n",
    "    for line in ax.lines[:-1]:  # Set line colors for all lines except the mean line\n",
    "        line.set_color('gray')\n",
    "\n",
    "g.set_axis_labels('Epoch', 'Memory (MB)')\n",
    "g.set_titles('{col_name}')\n",
    "\n",
    "axes = g.axes.flatten()\n",
    "axes[0].legend(['Individual Runs', 'Mean'], loc='center right')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'../../report/charts/memory_usage_{dataset}.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f788a9c4",
   "metadata": {},
   "source": [
    "### CPU Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380361ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot Memory Usage\n",
    "References:\n",
    "- https://seaborn.pydata.org/generated/seaborn.lineplot.html\n",
    "- https://seaborn.pydata.org/examples/timeseries_facets.html\n",
    "- https://stackoverflow.com/questions/62667158/how-do-i-increase-the-line-thickness-for-sns-lineplot\n",
    "\"\"\"\n",
    "try:\n",
    "    if COMMON_CELLS:\n",
    "        pass\n",
    "except NameError:\n",
    "    from IPython.display import Javascript\n",
    "    Javascript(\"Jupyter.notebook.execute_cells([0,1])\") \n",
    "\n",
    "cpu_data = []\n",
    "for idx, model in enumerate(models):\n",
    "    individual_runs = accuracy_df[accuracy_df['moe_type'] == model]\n",
    "    for _, row in individual_runs.iterrows():\n",
    "        cpu_data.append({\n",
    "            'epoch': row['epoch'],\n",
    "            'cpu_usage': row['profiling_total_cpu_time'],\n",
    "            'moe_type': model,\n",
    "            'friendly_name': models_friendly_names.get(model, model),\n",
    "            'hash': row['hash']\n",
    "        })\n",
    "\n",
    "cpu_df = pd.DataFrame(cpu_data)\n",
    "\n",
    "# Calculate mean\n",
    "cpu_mean_data = cpu_df.groupby(['friendly_name', 'epoch'])['cpu_usage'].mean().reset_index()\n",
    "cpu_mean_data['line_type'] = 'Mean'\n",
    "\n",
    "g = sns.FacetGrid(cpu_df, col='friendly_name', col_wrap=3, height=4, aspect=1.2, sharey=False)\n",
    "\n",
    "# Plot individual runs\n",
    "g.map_dataframe(sns.lineplot, x='epoch', y='cpu_usage', units='hash', estimator=None, alpha=0.6, linewidth=1.5, marker='o', markersize=3)\n",
    "\n",
    "# Overlay mean lines to make it stand out\n",
    "def add_cpu_mean_line(data, **kwargs):\n",
    "    color = MOE_ARCH_COLOR_DICT.get(data.moe_type.iloc[0], 'gray')\n",
    "    mean_by_epoch = data.groupby('epoch')['cpu_usage'].mean()\n",
    "    sns.lineplot(mean_by_epoch, label='Mean', linewidth=3, color=color)\n",
    "\n",
    "g.map_dataframe(add_cpu_mean_line)\n",
    "\n",
    "# Set individual run colors to gray\n",
    "for ax in g.axes.flatten():\n",
    "    for line in ax.lines[:-1]:  # Set line colors for all lines except the mean line\n",
    "        line.set_color('gray')\n",
    "\n",
    "g.set_axis_labels('Epoch', 'CPU Time (sec.)')\n",
    "g.set_titles('{col_name}')\n",
    "\n",
    "axes = g.axes.flatten()\n",
    "axes[0].legend(['Individual Runs', 'Mean'], loc='center right')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'../../report/charts/cpu_usage_{dataset}.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31a2f2c",
   "metadata": {},
   "source": [
    "## Expert Activation Heatmaps\n",
    "\n",
    "The following cells plot and save heatmaps for each models expert activations. For this, a separate query with the aim repo is run. Since the query can take a long time to execute the results are saved in the working directory as a csv file for subsequent use and experimentation.\n",
    "\n",
    "The expert segmentation architecture's data is plotted separateley because it has double the amount of experts, hence a single plot for all architectures would be harder to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10fa91c",
   "metadata": {
    "custom": {
     "metadata": {
      "tags": [
       "skip-execution"
      ]
     }
    },
    "language": "python"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Query for Expert Activations\n",
    "Note: THIS IS A VERY SLOW OPERATION - Hence why the data is written to disk for subsequent usage\n",
    "\"\"\"\n",
    "try:\n",
    "    if COMMON_CELLS:\n",
    "        pass\n",
    "except NameError:\n",
    "    from IPython.display import Javascript\n",
    "    Javascript(\"Jupyter.notebook.execute_cells([0,1])\") \n",
    "\n",
    "from aim.storage.context import Context\n",
    "\n",
    "all_rows = []\n",
    "ac_df = pd.DataFrame()\n",
    "for t in repo.iter_runs():\n",
    "    m = t.metrics()\n",
    "    for metric in m:\n",
    "        if metric.name.startswith('expert_'):\n",
    "            ac_row = {}\n",
    "            ac_row['hash'] = t.hash \n",
    "            ac_row['tags'] = t.props.tags\n",
    "            ac_row['name'] = metric.name\n",
    "            ac_row['values'] = metric.values.values_list()\n",
    "            ac_row['context'] = metric.context.to_dict()\n",
    "            ac_df = pd.concat([ac_df, pd.DataFrame([ac_row])], axis=0)\n",
    "    \n",
    "\n",
    "ac_df.to_csv(f'expert_activations_{dataset}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150bf1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot Expert Activations Heatmap\n",
    "References:\n",
    "- https://www.sciencedirect.com/topics/engineering/shannon-entropy\n",
    "- https://stackoverflow.com/questions/49973537/shannons-entropy-on-an-array-containing-zeros\n",
    "\"\"\"\n",
    "try:\n",
    "    if COMMON_CELLS:\n",
    "        pass\n",
    "except NameError:\n",
    "    from IPython.display import Javascript\n",
    "    Javascript(\"Jupyter.notebook.execute_cells([0,1])\") \n",
    "\n",
    "import ast\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# Calculate Shannon entropy for each model (column)\n",
    "def shannon_entropy_normalized(activations):\n",
    "    # Remove zero values as they do not contribute to entropy\n",
    "    \n",
    "    if isinstance(activations, list):\n",
    "        non_zero_values = np.array(activations)\n",
    "        non_zero_values = non_zero_values[non_zero_values > 0]\n",
    "        if len(non_zero_values) <= 1:\n",
    "            return 0.0\n",
    "    elif isinstance(activations, np.ndarray):\n",
    "        non_zero_values = activations[activations > 0]\n",
    "        if len(non_zero_values) <= 1:\n",
    "            return 0.0\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "    probabilities = non_zero_values / non_zero_values.sum()\n",
    "    shannon_ent = entropy(probabilities, base=2)\n",
    "    \n",
    "    # Normalize by max possible entropy (log2(n) where n is number of non-zero experts)\n",
    "    # See report for formula and references\n",
    "    max_entropy = np.log2(len(non_zero_values))\n",
    "    normalized_entropy = shannon_ent / max_entropy if max_entropy > 0 else 0\n",
    "    \n",
    "    return normalized_entropy\n",
    "\n",
    "df = pd.read_csv(f'expert_activations_{dataset}.csv', index_col=0)\n",
    "df_eval = df[df['context'].apply(lambda x: eval(x)['subset']) == 'val']\n",
    "\n",
    "# Add model name from tags\n",
    "df_eval['model'] = df_eval['tags'].apply(lambda x: next((tag for tag in eval(x) if tag in models_friendly_names.keys()), 'None')).copy()\n",
    "df_eval = df_eval.dropna(subset=['model'])\n",
    "df_eval['values'] = df_eval['values'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x) \n",
    "df_eval = df_eval.explode('values')\n",
    "df_eval['values'] = df_eval['values'].astype(int)\n",
    "\n",
    "df_grouped_before_aggregate = df_eval.groupby(['model', 'name', 'hash'])['values'].max().reset_index()\n",
    "df_grouped = df_grouped_before_aggregate.groupby(['model', 'name'])['values'].mean().reset_index()\n",
    "\n",
    "# Pivot\n",
    "df_pivot = df_grouped.pivot(index='name', columns='model', values='values')\n",
    "df_pivot = df_pivot.fillna(0)\n",
    "df_pivot = df_pivot.sort_index(axis=0, ascending=False)\n",
    "\n",
    "for i in range(2): # Create a separate expert_segmentation heatmap. expert_segmentation experiments have 16, instead of 8 experts, which makes a single heatmap containing all experts harder to read.\n",
    "    if i == 0:\n",
    "        df_pivot_filtered = df_pivot.drop(columns=['expert_segmentation', 'ffn'], errors='ignore')\n",
    "    else:\n",
    "        df_pivot_filtered = df_pivot.loc[:, ['expert_segmentation']]\n",
    "        \n",
    "    df_pivot_filtered = df_pivot_filtered[df_pivot_filtered.sum(axis=1) > 0]\n",
    "        \n",
    "    # Calculate totals and entropy for each model\n",
    "    totals_row = df_pivot_filtered.sum(axis=0)\n",
    "    entropy_row = df_pivot_filtered.apply(shannon_entropy_normalized, axis=0)\n",
    "    \n",
    "    # Calculate relative weights\n",
    "    df_proportions = df_pivot_filtered.div(df_pivot_filtered.sum(axis=0), axis=1)\n",
    "    weight_data = []\n",
    "    for expert_idx in df_pivot_filtered.index:\n",
    "        for model in df_pivot_filtered.columns:\n",
    "            relative_weight = df_proportions.loc[expert_idx, model]\n",
    "            activation_count = df_pivot_filtered.loc[expert_idx, model]\n",
    "            \n",
    "            weight_data.append({\n",
    "                'name': expert_idx,\n",
    "                'model': model,\n",
    "                'relative_weight': relative_weight,  \n",
    "                'activation_count': activation_count,\n",
    "                'model_entropy': entropy_row[model]\n",
    "            })\n",
    "    \n",
    "    df_weight_long = pd.DataFrame(weight_data) # Relplot accepts only long format data\n",
    "    \n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    cmap = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "    \n",
    "    g = sns.relplot(data=df_weight_long, \n",
    "                    x=\"model\", \n",
    "                    y=\"name\",\n",
    "                    hue=\"relative_weight\", \n",
    "                    size=\"relative_weight\",  \n",
    "                    palette=cmap, \n",
    "                    sizes=(100, 1000),  \n",
    "                    height=8,\n",
    "                    kind=\"scatter\",\n",
    "                    aspect=1.2)\n",
    "\n",
    "    entropy_info_str = \" | \".join([\n",
    "        f\"{col}: Entropy={ent:.3f}\" \n",
    "        for col, ent in zip(entropy_row.index, entropy_row.values)\n",
    "    ])\n",
    "\n",
    "    # Remove the SNS legend and instead use the Matplotlib legend because labelspacing does not seem to work in SNS\n",
    "    g.despine(left=True, bottom=True)\n",
    "    g.set_axis_labels(\"Model\", \"Expert\")\n",
    "    g.legend.remove()\n",
    "    plt.legend(labelspacing=1.8, loc='center right', fancybox=False, bbox_to_anchor=(1.35, 0.5), title=\"Relative Weight\", title_fontsize='12', fontsize='11', frameon=False)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if i == 0:\n",
    "        plt.savefig(f'../../report/charts/expert_activations_heatmap_{dataset}.png', dpi=300, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.savefig(f'../../report/charts/expert_segmentation_heatmap_{dataset}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5751312",
   "metadata": {},
   "source": [
    "## Shannon Equiprobability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eed600",
   "metadata": {},
   "source": [
    "### Aggregate Shannon Equiprobability\n",
    "\n",
    "This cell calculates the Shannon Equiprobabilty for each model after the final training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325617ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Print Shannon Equiprobability Table\n",
    "\"\"\"\n",
    "try:\n",
    "    if COMMON_CELLS:\n",
    "        pass\n",
    "except NameError:\n",
    "    from IPython.display import Javascript\n",
    "    Javascript(\"Jupyter.notebook.execute_cells([0,1])\") \n",
    "\n",
    "\n",
    "print(f\"Shannon Entropy {dataset}\")\n",
    "print(\"=\" * 50)\n",
    "for model in df_pivot.columns:\n",
    "    ent = shannon_entropy_normalized(df_pivot[model])\n",
    "    total = df_pivot[model].sum()\n",
    "    active_experts = (df_pivot[model] > 0).sum()\n",
    "    print(f\"{model:20s}: {ent:.3f} (Total: {total:.0f}, Total activated experts: {active_experts})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920e63db",
   "metadata": {},
   "source": [
    "### Accuracy vs Final Shannon Equiprobability\n",
    "\n",
    "This cell calculates and plots the equiprobability and relates it to the models accuracy at various stages of training (see code comments for how to configure this). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72440a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot Equiprobability and Accuracy \n",
    "Plotted for each run and epoch for models with weighted activations\n",
    "References: \n",
    "- https://realpython.com/numpy-scipy-pandas-correlation-python/\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    if COMMON_CELLS:\n",
    "        pass\n",
    "except NameError:\n",
    "    from IPython.display import Javascript\n",
    "    Javascript(\"Jupyter.notebook.execute_cells([0,1])\") \n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "table = accuracy_df[['hash', 'epoch', 'accuracy', 'expert_activations']].copy()\n",
    "table['shannon'] = table.apply(lambda row: shannon_entropy_normalized(row['expert_activations']), axis=1)\n",
    "table.drop(columns=['expert_activations'], inplace=True)\n",
    "table = table.groupby(['hash', 'epoch']).agg({'accuracy': 'first', 'shannon': 'first'}).reset_index()\n",
    "\n",
    "table = table[(table['shannon'] != 0) & (table['shannon'] != 1)]\n",
    "table_shannon = table[table['epoch'] == 20] # Use Shannon from this epoch\n",
    "table_accuracy = table[table['epoch'] == 20] # Use accuracy from this epoch\n",
    "table = pd.concat([table_shannon, table_accuracy], axis=0)  \n",
    "\n",
    "def correlation_text(corr):\n",
    "    abs_corr = abs(float(corr))\n",
    "    if abs_corr < 0.1:\n",
    "        return \"negligible\"\n",
    "    elif abs_corr < 0.3:\n",
    "        return \"weak\"\n",
    "    elif abs_corr < 0.5:\n",
    "        return \"moderate\"\n",
    "    elif abs_corr < 0.7:\n",
    "        return \"strong\"\n",
    "    else:\n",
    "        return \"very strong\"\n",
    "\n",
    "print(f\"Shannon entropy range: {table['shannon'].min():.4f} to {table['shannon'].max():.4f}\")\n",
    "print(f\"Accuracy range: {table['accuracy'].min():.4f} to {table['accuracy'].max():.4f}\")\n",
    "\n",
    "shannon_vals = table['shannon'].astype(float).values\n",
    "accuracy_vals = table['accuracy'].astype(float).values\n",
    "\n",
    "pearson_corr, pearson_p = pearsonr(shannon_vals, accuracy_vals)\n",
    "spearman_corr, spearman_p = spearmanr(shannon_vals, accuracy_vals)\n",
    "\n",
    "print(\"\\nCorrelation:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Pearson correlation: {pearson_corr:.4f} (p-value: {pearson_p:.4f})\")\n",
    "print(f\"Spearman correlation: {spearman_corr:.4f} (p-value: {spearman_p:.4f})\")\n",
    "\n",
    "print(f\"Pearson correlation strength: {correlation_text(pearson_corr)}\")\n",
    "print(f\"Spearman correlation strength: {correlation_text(spearman_corr)}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(shannon_vals, accuracy_vals, alpha=0.6, s=30)\n",
    "plt.xlabel('Shannon Entropy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(f'Pearson r = {pearson_corr:.3f}, Spearman r = {spearman_corr:.3f}')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "if abs(pearson_corr) > 0.1:\n",
    "    z = np.polyfit(shannon_vals, accuracy_vals, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(shannon_vals, p(shannon_vals), \"r--\", alpha=0.8, linewidth=2, label=f'Trend line (r={pearson_corr:.3f})')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = f'../../report/charts/accuracy_vs_shannon_entropy_{dataset}_2020.png'\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight', transparent=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205a28b1",
   "metadata": {},
   "source": [
    "## Stratified Bootstrap CI\n",
    "\n",
    "This cell calculates the stratified bootstrap intervals for every models accuracies.\n",
    "\n",
    "Note: The code in the next three cells is taken from Agarwal et al. (2022) with minimal adjustments._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a6984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prepare Score Distributions\n",
    "References: \n",
    "- https://seaborn.pydata.org/generated/seaborn.boxplot.html\n",
    "- https://seaborn.pydata.org/generated/seaborn.violinplot.html\n",
    "- https://stat20.berkeley.edu/fall-2024/3-generalization/09-bootstrapping/notes.html\n",
    "- https://arxiv.org/pdf/2108.13264#page=5.73\n",
    "- https://colab.research.google.com/drive/1a0pSD-1tWhMmeJeeoyZM1A-HCW3yf1xR?usp=sharing#scrollTo=LnNa7O9xCuKA \n",
    "\"\"\"\n",
    "\n",
    "from networkx import is_empty\n",
    "\n",
    "\n",
    "try:\n",
    "    if COMMON_CELLS:\n",
    "        pass\n",
    "except NameError:\n",
    "    from IPython.display import Javascript\n",
    "    Javascript(\"Jupyter.notebook.execute_cells([0,1])\") \n",
    "\n",
    "accuracy_val_end = accuracy_df[accuracy_df['epoch'].isin(range(21))]\n",
    "scores = accuracy_val_end[accuracy_val_end['context'] == 'val'] \\\n",
    "    .sort_values(by=['hash', 'epoch']) \\\n",
    "    .drop(columns=['context', 'step', 'epoch', 'loss', 'profiling_total_cpu_time', 'profiling_memory_usage']) \\\n",
    "    .dropna(subset=['accuracy'])\n",
    "\n",
    "score_data_dict = {\n",
    "    key: np.array([]) for key in accuracy_val_end['moe_type'].unique()\n",
    "}\n",
    "\n",
    "for key in score_data_dict.keys():\n",
    "    nda = []\n",
    "    for hash in scores[scores['moe_type'] == key]['hash'].unique():\n",
    "        mid = scores[(scores['moe_type'] == key) & (scores['hash'] == hash)].drop(columns=['moe_type', 'hash'])\n",
    "        if len(mid['accuracy'].values) == 20: # Only include runs that completed all 20 epochs\n",
    "            nda.append(mid['accuracy'].values) # runs x tasks\n",
    "    score_data_dict[key] = np.array(nda).astype(float)\n",
    "\n",
    "score_data_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52193af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot Interval Estimates\n",
    "References: \n",
    "- https://seaborn.pydata.org/generated/seaborn.boxplot.html\n",
    "- https://seaborn.pydata.org/generated/seaborn.violinplot.html\n",
    "- https://stat20.berkeley.edu/fall-2024/3-generalization/09-bootstrapping/notes.html\n",
    "- https://arxiv.org/pdf/2108.13264#page=5.73\n",
    "- https://colab.research.google.com/drive/1a0pSD-1tWhMmeJeeoyZM1A-HCW3yf1xR?usp=sharing#scrollTo=LnNa7O9xCuKA \n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    if COMMON_CELLS:\n",
    "        pass\n",
    "except NameError:\n",
    "    from IPython.display import Javascript\n",
    "    Javascript(\"Jupyter.notebook.execute_cells([0,1])\") \n",
    "\n",
    "from rliable import library as rly\n",
    "from rliable import metrics\n",
    "from rliable import plot_utils\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# Matplotlib params\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import rc\n",
    "\n",
    "rcParams['legend.loc'] = 'best'\n",
    "rcParams['pdf.fonttype'] = 42\n",
    "rcParams['ps.fonttype'] = 42\n",
    "\n",
    "rc('text', usetex=False)\n",
    "\n",
    "def set_axes(ax, xlim, ylim, xlabel, ylabel):\n",
    "  ax.set_xlim(xlim)\n",
    "  ax.set_ylim(ylim)\n",
    "  ax.set_xlabel(xlabel, labelpad=14)\n",
    "  ax.set_ylabel(ylabel, labelpad=14)\n",
    " \n",
    "def set_ticks(ax, xticks, xticklabels, yticks, yticklabels):\n",
    "  ax.set_xticks(xticks)\n",
    "  ax.set_xticklabels(xticklabels)\n",
    "  ax.set_yticks(yticks)\n",
    "  ax.set_yticklabels(yticklabels)\n",
    "\n",
    "def decorate_axis(ax, wrect=10, hrect=10, labelsize='large'):\n",
    "  # Hide the right and top spines\n",
    "  ax.spines['right'].set_visible(False)\n",
    "  ax.spines['top'].set_visible(False)\n",
    "  ax.spines['left'].set_linewidth(2)\n",
    "  ax.spines['bottom'].set_linewidth(2)\n",
    "  ax.tick_params(length=0.1, width=0.1, labelsize=labelsize)\n",
    "  ax.spines['left'].set_position(('outward', hrect))\n",
    "  ax.spines['bottom'].set_position(('outward', wrect))\n",
    "\n",
    "def score_normalization(res_dict, min_scores, max_scores):\n",
    "  norm_scores = {}\n",
    "  for game, scores in res_dict.items():\n",
    "    norm_scores[game] = (scores - min_scores[game])/(max_scores[game] - min_scores[game])\n",
    "  return norm_scores\n",
    "\n",
    "def convert_to_matrix(score_dict):\n",
    "   keys = sorted(list(score_dict.keys()))\n",
    "   return np.stack([score_dict[k] for k in keys], axis=1)\n",
    "\n",
    "def plot_score_hist(score_matrix, bins=20, figsize=(28, 14), fontsize='xx-large', N=6, extra_row=1, names=None):\n",
    "  num_tasks = score_matrix.shape[1]\n",
    "  N1 = (num_tasks // N) + extra_row\n",
    "  fig, ax = plt.subplots(nrows=N1, ncols=N, figsize=figsize)\n",
    "  for i in range(N):\n",
    "    for j in range(N1):\n",
    "      idx = j * N + i\n",
    "      if idx < num_tasks:\n",
    "        ax[j, i].set_title(names[idx], fontsize=fontsize)\n",
    "        sns.histplot(score_matrix[:, idx], bins=bins, ax=ax[j,i], kde=True)\n",
    "      else:\n",
    "        ax[j, i].axis('off')\n",
    "      decorate_axis(ax[j, i], wrect=5, hrect=5, labelsize='xx-large')\n",
    "      ax[j, i].xaxis.set_major_locator(plt.MaxNLocator(4))\n",
    "      if idx % N == 0:\n",
    "        ax[j, i].set_ylabel('Count', size=fontsize)\n",
    "      else:\n",
    "        ax[j, i].yaxis.label.set_visible(False)\n",
    "      ax[j, i].grid(axis='y', alpha=0.1)\n",
    "  return fig\n",
    "\n",
    "StratifiedBootstrap = rly.StratifiedBootstrap\n",
    "\n",
    "IQM = lambda x: metrics.aggregate_iqm(x) # Interquartile Mean\n",
    "OG = lambda x: metrics.aggregate_optimality_gap(x, 0.99) # Optimality Gap\n",
    "MEAN = lambda x: metrics.aggregate_mean(x)\n",
    "MEDIAN = lambda x: metrics.aggregate_median(x)\n",
    "\n",
    "moe_arch_score_dict = {key: val[:last_runs_to_consider] for key, val in score_data_dict.items()}\n",
    "\n",
    "def subsample_scores(score_dict, n=5, replace=False):\n",
    "  subsampled_dict = {}\n",
    "  total_samples = len(score_dict[list(score_dict.keys())[0]])\n",
    "  for game, scores in score_dict.items():\n",
    "    indices = np.random.choice(range(total_samples), size=n, replace=replace)\n",
    "    subsampled_dict[game] = scores[indices]\n",
    "  return subsampled_dict\n",
    "\n",
    "def subsample_scores_mat(score_mat, num_samples=5, replace=False):\n",
    "  total_samples, num_games = score_mat.shape\n",
    "  subsampled_scores = np.empty((num_samples, num_games))\n",
    "  for i in range(num_games):\n",
    "    indices = np.random.choice(total_samples, size=num_samples, replace=replace)\n",
    "    subsampled_scores[:, i] = score_mat[indices, i]\n",
    "  return subsampled_scores\n",
    "\n",
    "def subsample_seeds(score_mat, num_samples=5, replace=False):\n",
    "  indices = np.random.choice(score_mat.shape[0], size=num_samples, replace=replace)\n",
    "  return score_mat[indices]\n",
    "\n",
    "def batch_subsample_seeds(score_mat, num_samples=5, batch_size=100, replace=False):\n",
    "  indices = [\n",
    "    np.random.choice(score_mat.shape[0], size=num_samples, replace=replace)\n",
    "    for _ in range(batch_size)\n",
    "  ]\n",
    "  return (score_mat[idx] for idx in indices)\n",
    "\n",
    "def subsample_scores_mat_with_replacement(score_mat, num_samples=5):\n",
    "  total_samples, num_games = score_mat.shape\n",
    "  indices = np.random.choice(total_samples, size=(num_samples, num_games), replace=True)\n",
    "  col_indices =  np.expand_dims(np.arange(num_games), axis=0)\n",
    "  col_indices = np.repeat(col_indices, num_samples, axis=0)\n",
    "  subsampled_scores = score_mat[indices, col_indices]\n",
    "  return subsampled_scores\n",
    "\n",
    "SIZES = [3, 5, 10, 25, 50, 100]\n",
    "\n",
    "def calc_aggregate_fn(score_data, num_samples=5, total_n=20000, aggregate_fn=MEDIAN, replace=False):\n",
    "  subsampled_scores = batch_subsample_seeds(score_data, num_samples, batch_size=total_n, replace=replace)\n",
    "  aggregates = [aggregate_fn(scores) for scores in subsampled_scores]\n",
    "  return np.array(aggregates)\n",
    "\n",
    "def calculate_aggregate_varying_sizes(score_matrix, aggregate_fn, total_n=20000, sizes=None, replace=False):\n",
    "  agg_dict = {}\n",
    "  if sizes is None:\n",
    "    sizes = SIZES\n",
    "  for size in sizes:\n",
    "    agg_dict[n] = calc_aggregate_fn(score_matrix, num_samples=size, aggregate_fn=aggregate_fn, total_n=total_n, replace=replace)\n",
    "    print('Mean Aggregate: {}'.format(np.mean(agg_dict[n])))\n",
    "  return agg_dict\n",
    "\n",
    "def CI(bootstrap_dist, stat_val=None, alpha=0.05, is_pivotal=False):\n",
    "    \"\"\"\n",
    "    Get the bootstrap confidence interval for a given distribution.\n",
    "    Args:\n",
    "      bootstrap_distribution: numpy array of bootstrap results.\n",
    "      stat_val: The overall statistic that this method is attempting to\n",
    "        calculate error bars for. Default is None.\n",
    "      alpha: The alpha value for the confidence intervals.\n",
    "      is_pivotal: if true, use the pivotal (reverse percentile) method. \n",
    "        If false, use the percentile method.\n",
    "    Returns:\n",
    "      (low, high): The lower and upper limit for `alpha` x 100% CIs.\n",
    "      val: The median value of the bootstrap distribution if `stat_val` is None\n",
    "        else `stat_val`.\n",
    "    \"\"\"\n",
    "    # Adapted from https://pypi.org/project/bootstrapped\n",
    "    if is_pivotal:\n",
    "      assert stat_val is not None, 'Please pass the statistic for a pivotal'\n",
    "      'confidence interval' \n",
    "      low = 2 * stat_val - np.percentile(bootstrap_dist, 100 * (1 - alpha / 2.))\n",
    "      val = stat_val\n",
    "      high = 2 * stat_val - np.percentile(bootstrap_dist, 100 * (alpha / 2.))\n",
    "    else:\n",
    "      low = np.percentile(bootstrap_dist, 100 * (alpha / 2.))\n",
    "      val = np.percentile(bootstrap_dist, 50)\n",
    "      high = np.percentile(bootstrap_dist, 100 * (1 - alpha / 2.))\n",
    "    return (low, high), val\n",
    "\n",
    "aggregate_func = lambda x: np.array([MEDIAN(x), IQM(x), MEAN(x), OG(x)])\n",
    "aggregate_scores, aggregate_interval_estimates = rly.get_interval_estimates(moe_arch_score_dict, aggregate_func, task_bootstrap=False, reps=bootstrap_reps, random_state=RAND_STATE)\n",
    "\n",
    "algorithms = list(moe_arch_score_dict.keys())\n",
    "fig, axes = plot_utils.plot_interval_estimates(\n",
    "    aggregate_scores, \n",
    "    aggregate_interval_estimates,\n",
    "    metric_names = ['Median', 'IQM', 'Mean', 'Optimality Gap'],\n",
    "    algorithms=algorithms,\n",
    "    colors=MOE_ARCH_COLOR_DICT,\n",
    "    xlabel_y_coordinate=-0.16,\n",
    "    xlabel='Normalized Score')\n",
    "\n",
    "plt.savefig(f'../../report/charts/bootstrap_interval_estimates_{dataset}.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9c8624",
   "metadata": {},
   "source": [
    "## Probability of Improvement\n",
    "\n",
    "Note: The following code is taken from Agarwal et al. (2022) with minimal adjustments\n",
    "\n",
    "References:\n",
    "- https://stat20.berkeley.edu/fall-2024/3-generalization/09-bootstrapping/notes.html\n",
    "- https://arxiv.org/pdf/2108.13264#page=5.73\n",
    "- https://colab.research.google.com/drive/1a0pSD-1tWhMmeJeeoyZM1A-HCW3yf1xR?usp=sharing#scrollTo=LnNa7O9xCuKA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7842954",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot Probability of Improvement\n",
    "References: \n",
    "- https://seaborn.pydata.org/generated/seaborn.boxplot.html\n",
    "- https://seaborn.pydata.org/generated/seaborn.violinplot.html\n",
    "- https://stat20.berkeley.edu/fall-2024/3-generalization/09-bootstrapping/notes.html\n",
    "- https://arxiv.org/pdf/2108.13264#page=5.73\n",
    "- https://colab.research.google.com/drive/1a0pSD-1tWhMmeJeeoyZM1A-HCW3yf1xR?usp=sharing#scrollTo=LnNa7O9xCuKA \n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    if COMMON_CELLS:\n",
    "        pass\n",
    "except NameError:\n",
    "    from IPython.display import Javascript\n",
    "    Javascript(\"Jupyter.notebook.execute_cells([0,1])\")\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    all_pairs =  {}\n",
    "    for alg in (algorithms):\n",
    "        if alg == algorithm:\n",
    "            continue\n",
    "        pair_name = f'{algorithm}:{alg}'\n",
    "        all_pairs[pair_name] = (moe_arch_score_dict[algorithm], moe_arch_score_dict[alg])\n",
    "    \n",
    "    probabilities, probability_cis = {}, {}\n",
    "    probabilities, probability_cis = rly.get_interval_estimates(all_pairs, metrics.probability_of_improvement, reps=bootstrap_reps, random_state=RAND_STATE)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "    h = 0.6\n",
    "    algorithm_labels = []\n",
    "\n",
    "    for i, (alg_pair, prob) in enumerate(probabilities.items()):\n",
    "        _, alg1 = alg_pair.split(':')\n",
    "        algorithm_labels.append(alg1)\n",
    "        (l, u) = probability_cis[alg_pair]\n",
    "        ax.barh(y=i, width=u-l, height=h, left=l, color=MOE_ARCH_COLOR_DICT[alg1], alpha=0.75)\n",
    "        ax.vlines(x=prob, ymin=i-7.5 * h/16, ymax=i+(6*h/16), color='k', alpha=0.85)\n",
    "        ax.set_yticks(range(len(algorithm_labels)))\n",
    "        ax.set_yticklabels(algorithm_labels)\n",
    "\n",
    "    ax.set_title(fr'P({algorithm} > $Y$)', size='xx-large')\n",
    "    plot_utils._annotate_and_decorate_axis(ax, labelsize='xx-large', ticklabelsize='xx-large')\n",
    "    ax.set_ylabel(r'Algorithm $Y$', size='xx-large')\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(4))\n",
    "    fig.subplots_adjust(wspace=0.25, hspace=0.45)\n",
    "    \n",
    "    fig.savefig(f'../../report/charts/probability_of_improvement_{algorithm}_{dataset}.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af67cac6",
   "metadata": {},
   "source": [
    "## Hardware Usage\n",
    "\n",
    "This cell calculates the hardware usage and relates it to each models accuracy.\n",
    "\n",
    "MACs, Memory, CPU and Accuracy each are plotted with their own vertical bar. For each experiment run a line is drawn connecting the respective points on the bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7cca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot Hardware Usage\n",
    "Reference: The visual presentation of the data in this section is heavily inspired by the aimStack UI's metrics explorer, though no code was copied.\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    if COMMON_CELLS:\n",
    "        pass\n",
    "except NameError:\n",
    "    from IPython.display import Javascript\n",
    "    Javascript(\"Jupyter.notebook.execute_cells([0,1])\") \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "parallel_data = []\n",
    "for _, row in accuracy_df.iterrows():\n",
    "    model = row['moe_type']\n",
    "    friendly_name = models_friendly_names.get(model, model)\n",
    "    \n",
    "    parallel_data.append({\n",
    "        'model': friendly_name,\n",
    "        'moe_type': model,\n",
    "        'hash': row['hash'],\n",
    "        'memory_usage': row['profiling_memory_usage'],\n",
    "        'cpu_time': row['profiling_total_cpu_time'],\n",
    "        'epoch': row['epoch'],\n",
    "        'accuracy': row['accuracy'],\n",
    "        'macs': row['macs']\n",
    "    })\n",
    "\n",
    "parallel_df = pd.DataFrame(parallel_data)\n",
    "parallel_df = parallel_df.fillna(method='ffill') # Upfill missing macs values as they are only tracked for the first epoch\n",
    "\n",
    "# Filter to final epoch only\n",
    "parallel_df_final = parallel_df[parallel_df['epoch'] == parallel_df['epoch'].max()].copy()\n",
    "\n",
    "# Set up x positions for metrics\n",
    "x_positions = [0, 1, 2, 3]\n",
    "x_labels = ['MACs', 'Memory Usage\\n(MB)', 'CPU Time\\n(seconds)', 'Accuracy']\n",
    "models = [model for model in parallel_df['moe_type'].unique() if model]\n",
    "n_models = len(models)\n",
    "\n",
    "# Grid dimensions\n",
    "cols = 2\n",
    "rows = (n_models + cols - 1) // cols  # Ceiling division\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(15, 4 * rows))\n",
    "if rows == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each model in its own subplot\n",
    "for idx, model in enumerate(models):\n",
    "    ax = axes[idx]\n",
    "\n",
    "    # Normalize to make visualizations nicer\n",
    "    scaler = MinMaxScaler()\n",
    "    metrics_to_plot = ['macs', 'memory_usage', 'cpu_time', 'accuracy'] \n",
    "    model_data = parallel_df_final[parallel_df_final['moe_type'] == model].copy()\n",
    "    model_data[metrics_to_plot] = scaler.fit_transform(model_data[metrics_to_plot])\n",
    "\n",
    "    color = MOE_ARCH_COLOR_DICT.get(model, 'gray')\n",
    "    friendly_name = models_friendly_names.get(model, model)\n",
    "    \n",
    "    # Plot individual runs for this model\n",
    "    for _, row in model_data.iterrows():\n",
    "        y_values = [row['macs'], row['memory_usage'], row['cpu_time'], row['accuracy']]\n",
    "        ax.plot(x_positions, y_values, color='lightgray')\n",
    "    \n",
    "    # Calculate and plot mean line\n",
    "    mean_values = [\n",
    "        model_data['macs'].mean(),\n",
    "        model_data['memory_usage'].mean(), \n",
    "        model_data['cpu_time'].mean(),\n",
    "        model_data['accuracy'].mean()\n",
    "    ]\n",
    "\n",
    "    ax.plot(x_positions, mean_values, 'o--', color=color, linewidth=3, markersize=8, alpha=1.0)\n",
    "\n",
    "    # Customize subplot\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(x_labels, fontsize=10)\n",
    "    ax.set_title(friendly_name, fontsize=12, y=1.05)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # Add vertical reference lines at each axis\n",
    "    for x_pos in x_positions:\n",
    "        ax.axvline(x=x_pos, color='lightgray', alpha=0.5, linestyle='-', linewidth=0.8)\n",
    "    \n",
    "    macs_min = parallel_df_final['macs'].min()\n",
    "    macs_max = parallel_df_final['macs'].max()\n",
    "    ax.text(-0.15, 0, f'{macs_min:.0f}', transform=ax.transData, ha='right', va='center', fontsize=8, color='gray')\n",
    "    ax.text(-0.15, 1, f'{macs_max:.0f}', transform=ax.transData, ha='right', va='center', fontsize=8, color='gray')\n",
    "    \n",
    "    memory_min = parallel_df_final['memory_usage'].min()\n",
    "    memory_max = parallel_df_final['memory_usage'].max()\n",
    "    ax.text(1, 0, f'{memory_min:.0f}', transform=ax.transData, ha='center', va='top', fontsize=8, color='gray', rotation=0)\n",
    "    ax.text(1, 1, f'{memory_max:.0f}', transform=ax.transData, ha='center', va='bottom', fontsize=8, color='gray', rotation=0)\n",
    "\n",
    "    cpu_min = parallel_df_final['cpu_time'].min()\n",
    "    cpu_max = parallel_df_final['cpu_time'].max()\n",
    "    ax.text(2.15, 0, f'{cpu_min:.1f}', transform=ax.transData, ha='left', va='center', fontsize=8, color='gray')\n",
    "    ax.text(2.15, 1, f'{cpu_max:.1f}', transform=ax.transData, ha='left', va='center', fontsize=8, color='gray')\n",
    "\n",
    "    accuracy_min = parallel_df_final['accuracy'].min()\n",
    "    accuracy_max = parallel_df_final['accuracy'].max()\n",
    "    ax.text(3.15, 0, f'{accuracy_min:.1f}', transform=ax.transData, ha='left', va='center', fontsize=8, color='gray')\n",
    "    ax.text(3.15, 1, f'{accuracy_max:.1f}', transform=ax.transData, ha='left', va='center', fontsize=8, color='gray')\n",
    "\n",
    "    # Add intermediate scale markers\n",
    "    for i, (min_val, max_val, pos, suffix) in enumerate([\n",
    "        (macs_min, macs_max, 0, ''),\n",
    "        (memory_min, memory_max, 1, ''),\n",
    "        (cpu_min, cpu_max, 2, ''),\n",
    "        (accuracy_min, accuracy_max, 3, '')\n",
    "    ]):\n",
    "        # Add 25%, 50%, 75% markers\n",
    "        for y_pos in [0.25, 0.5, 0.75]:\n",
    "            val = min_val + (max_val - min_val) * y_pos\n",
    "            \n",
    "            # Small tick marks\n",
    "            ax.plot([pos - 0.02, pos + 0.02], [y_pos, y_pos], color='gray', alpha=0.6, linewidth=0.5)\n",
    "            ax.set_yticklabels([])\n",
    "\n",
    "            # We'll show a value label only in the vertical middle\n",
    "            if y_pos == 0.5:\n",
    "                if pos == 0:  # MACs - left side\n",
    "                    ax.text(pos - 0.08, y_pos, f'{val:.0f}', ha='right', va='center', fontsize=7, color='gray')\n",
    "                elif pos == 1:  # Memory - below\n",
    "                    ax.text(pos, y_pos - 0.05, f'{val:.0f}{suffix}', ha='center', va='top', fontsize=7, color='gray')\n",
    "                elif pos == 2:  # CPU - below\n",
    "                    ax.text(pos + 0.08, y_pos, f'{val:.1f}{suffix}', ha='center', va='center', fontsize=7, color='gray')\n",
    "                elif pos == 3:  # Accuracy - right side\n",
    "                    ax.text(pos + 0.08, y_pos, f'{val:.1f}{suffix}', ha='left', va='center', fontsize=7, color='gray')\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(n_models, len(axes)): \n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color='gray', linewidth=1.5, alpha=0.6, label='Individual Runs'),\n",
    "    Line2D([0], [0], color='black', linewidth=3, linestyle='--', label='Mean')\n",
    "]\n",
    "fig.legend(handles=legend_elements, loc='center right', bbox_to_anchor=(0.95, 1.0), fontsize=11)\n",
    "\n",
    "sns.despine(left=True, bottom=True, fig=fig)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(right=0.95)  \n",
    "\n",
    "plt.savefig(f'../../report/charts/hardware_usage_comparison_{dataset}.png', dpi=300, bbox_inches='tight', facecolor='white')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
